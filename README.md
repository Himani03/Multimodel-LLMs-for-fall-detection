# Multimodel-LLMs-for-fall-detection

The study presents a fall detection system that combines both video and sensor data using Large Language Models (LLMs). Traditional systems often rely only on wearables or cameras, which can be uncomfortable or raise privacy concerns. Our approach uses a mix of prompting techniques—like Tree-of-Thought (ToT), Chain-of-Thought (CoT), and One/Few/Zero-Shot examples—along with Retrieval-Augmented Generation (RAG) and lightweight fine-tuning using LoRA and Reinforcement Learning from Human Feedback (RLHF). We tested the system using the UR Fall Detection Dataset and found that ToT prompting and LoRA + RLHF fine-tuning gave the best results, with high accuracy and strong F1 scores. This system not only detects falls effectively in real-world settings but also shows promise for future use on lightweight, portable devices for real-time monitoring.
